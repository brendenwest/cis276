{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "6_data_wrangling.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brendenwest/cis276/blob/main/6_data_wrangling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8FdbbolrIZv"
      },
      "source": [
        "# Data Cleaning\n",
        "\n",
        "Techniques for cleaning & preparing data\n",
        "\n",
        "### Reading\n",
        "- Murach's, Chapter 6, 7\n",
        "- https://wesmckinney.com/book/data-cleaning\n",
        "\n",
        "### Learning Outcomes\n",
        "- how to find & fix missing values\n",
        "- how to simplify your data\n",
        "- how to fix data-type problems\n",
        "- how to work with indexes\n",
        "- how to apply functions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Cleaning\n",
        "\n",
        "Cleaning data is a crucial and often time-consuming step in data science.\n",
        "\n",
        "Data scientists might use pure Python, psndas, or other programming tools for this step. Examples here focus on pandas with a few other approaches for specific scenarios.\n",
        "\n",
        "Common tasks are:\n",
        "\n",
        "*   Handling missing data\n",
        "*   Simplifying data\n",
        "*   Data-type conversion\n",
        "\n"
      ],
      "metadata": {
        "id": "s7C0PycAAup_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Handling Missing Data\n",
        "\n",
        "Often data analysts need to account for missing data values.\n",
        "\n",
        "pandas uses the floating-point value `NaN` (Not a Number) to represent missing numerica data. This is a `sentinel` value that can be easily detected.\n",
        "\n",
        "The built-in Python `None` value is also treated as NaN.\n",
        "\n",
        "pandas has several methods for detecting NaN values in a Series or DataFrame:\n",
        "- isnull\n",
        "- notnull\n",
        "\n",
        "These methods can be used as filters in a data query.\n",
        "\n",
        "`data[data.notnull()]`\n",
        "\n",
        "Alternatively, programs can use `dropna` to filter axis labels where values may have missing data.\n",
        "\n",
        "`dropna` has options to control how many missing values a row or column should have to be dropped.\n",
        "\n",
        "**replace missing values**\n",
        "Sometimes it's more useful to replace missing data with a specific or interpreted value, using `fillna`.\n",
        "\n",
        "```\n",
        "df_2 = df.fillna(-1) # return new dataframe with -1 in place of missing values\n",
        "df.fillna(-1, inplace=True) # fill missing values with -1 in original dataframe\n",
        "```\n"
      ],
      "metadata": {
        "id": "VutiVeS4BTte"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Simplifying Data\n",
        "\n",
        "- **removing duplicates** - DataFrames have built-in methods to identify which rows are `duplicated` and to `drop_duplicates`. By default, these methods consider all columns, but programs can specify a subset.\n",
        "\n",
        "- **replacing values** - the `replace()` method is a simple approach for replacing values in a pandas object.\n",
        "\n",
        "- **handling outliers** - programs may want to find & replace or filter values that exceed some threshold."
      ],
      "metadata": {
        "id": "YC6I94lKBnKP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### String Conversion\n",
        "\n",
        "python has a wide range of built-in string methods. Some common ones are:\n",
        "  - **split** - generate an array of substrings from a string based on a delimiter\n",
        "  - **lowercase** - convert a string to lower case\n",
        "  - **uppercase** - convert a string to upper case\n",
        "  - **join** - combine strings with a delimiter\n",
        "  - **index** - determine where in a string a substring is first found\n",
        "  - **find** - determine if a string contains a substring\n",
        "  - **count** - number of occurences of a substring in a string\n",
        "  - **replace** - substitute occurrences of one pattern with another.\n",
        "\n",
        "\n",
        "**Regular Expressions** provide a (mostly) language-agnostic logical syntax for finding/matching string patterns in text.\n",
        "\n",
        "`regex` patterns can be applied to strings with python's [re module](https://docs.python.org/3/library/re.html).\n",
        "\n"
      ],
      "metadata": {
        "id": "pjqwCL4VB7dr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "text = \"foo    bar\\t baz  \\tqux\"\n",
        "\n",
        "# inline regex pattern\n",
        "re.split('\\s+', text)\n",
        "\n",
        "# reusable regex object\n",
        "regex = re.compile('\\s+')\n",
        "regex.split(text)"
      ],
      "metadata": {
        "id": "SsYBLniBCOLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1B4F38nxHhX"
      },
      "source": [
        "### Hierarchical Indexing\n",
        "\n",
        "- allows multiple index (MultiIndex) levels on an axis\n",
        "- either axis of a DataFrame can have a hierarchical index\n",
        "- partial indexing allows concise selection of data subsets\n",
        "- selections can be made on the `outer` or `inner` level of a MultiIndex\n",
        "- can be used to reshape data (using `stack` & `unstack`)\n",
        "- can be used for group-based operations\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fR2iF-PETfB"
      },
      "source": [
        "#### Creating hierarchical indexes\n",
        "\n",
        "Hierarchical indexes can be assigned to dataset by passing a multi-dimensional list for the `index` value, with each list item having the same length as the dataset axis. This creates a `MultiIndex` object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARXVyZrxDulM",
        "outputId": "1f3f4b20-a90c-4490-b40d-7f83b2ca04e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "data = pd.Series(np.random.randn(9),\n",
        " index=[['a', 'a', 'a', 'b', 'b', 'c', 'c', 'd', 'd'],\n",
        " [1, 2, 3, 1, 3, 1, 2, 2, 3]])\n",
        "print(data)\n",
        "print(data.index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a  1   -0.605719\n",
            "   2    0.123044\n",
            "   3    1.811644\n",
            "b  1    0.823819\n",
            "   3    0.385486\n",
            "c  1    0.327702\n",
            "   2   -0.159786\n",
            "d  2    0.869689\n",
            "   3   -1.515328\n",
            "dtype: float64\n",
            "MultiIndex([('a', 1),\n",
            "            ('a', 2),\n",
            "            ('a', 3),\n",
            "            ('b', 1),\n",
            "            ('b', 3),\n",
            "            ('c', 1),\n",
            "            ('c', 2),\n",
            "            ('d', 2),\n",
            "            ('d', 3)],\n",
            "           )\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSij_o5gEPzD"
      },
      "source": [
        "#### Reordering & Sorting Levels\n",
        "\n",
        "- `swaplevel` changes order of levels in a MultiIndex\n",
        "- `sort_index` sorts the dataset using only the values in a single level of the MultiIndex\n",
        "\n",
        "#### Summary Statistics by Level\n",
        "\n",
        "- Many pandas descriptive and summary statistics support specifying the level you want to aggregate by on a particular axis.\n",
        "\n",
        "#### Indexing with DataFrame columns\n",
        "\n",
        "- DataFrame's `set_index` function will create a new DataFrame using one or more of its columns as the index\n",
        "- index columns are removed from the DataFrame unless specified otherwise with `drop=False`\n",
        "- `reset_index` moves hierarchical index levels into the DataFrame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUH6j4_GIZ6G"
      },
      "source": [
        "### Data Aggregation\n",
        "\n",
        "Aggregations refer to any data transformation that produces scalar values from arrays.\n",
        "\n",
        "Programs can use built-in optimized aggregation methods, or custom functions.\n",
        "\n",
        "Programs can pass any function that aggregates an array to the `aggregate` or `agg` method of a GroupBy object.\n",
        "\n",
        "Custom aggregation functions are generally much slower than the built-in optimized functions.\n",
        "\n",
        "#### Column-wise & Multiple-function application\n",
        "\n",
        "Providing a list of functions or function names, results in a DataFrame with column names taken from the functions. Programs can over-ride the default column name:\n",
        "\n",
        "`grouped_pct.agg([('foo', 'mean'), ('bar', np.std), peak_to_peak])`\n",
        "\n",
        "You can specify a list of functions to apply to all of the columns or different functions per column.\n",
        "\n",
        "#### Aggregated data without row indexes\n",
        "\n",
        "By default, the aggregated data result has an index, potentially hierarchical, composed from the unique group key combinations. You can disable this behavior in most cases by passing `as_index=False` to groupby."
      ]
    }
  ]
}