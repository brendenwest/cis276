{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5_data_wrangling.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brendenwest/cis276/blob/main/5_data_wrangling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8FdbbolrIZv"
      },
      "source": [
        "# Data Wrangling\n",
        "\n",
        "Techniques for cleaning & preparing data \n",
        "\n",
        "### Reading\n",
        "- Murach's, Chapter 6, 7\n",
        " \n",
        "### Tutorials\n",
        "- https://www.datacamp.com/community/tutorials/pandas-multi-index\n",
        "- https://www.datacamp.com/community/tutorials/pandas-split-apply-combine-groupby\n",
        " \n",
        "### Learning Outcomes\n",
        "- how to find & fix missing values \n",
        "- how to simplify your data \n",
        "- how to fix data-type problems \n",
        "- how to combine & reshape DataFrames \n",
        "- how to work with indexes \n",
        "- how to apply functions \n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Cleaning\n",
        "\n",
        "Cleaning data is a crucial and often time-consuming step in data science.\n",
        "\n",
        "Data scientists might use pure Python, psndas, or other programming tools for this step. Examples here focus on pandas with a few other approaches for specific scenarios.\n",
        "\n",
        "Common tasks are:\n",
        "\n",
        "*   Handling missing data\n",
        "*   Simplifying data\n",
        "*   Data-type conversion\n",
        "\n"
      ],
      "metadata": {
        "id": "s7C0PycAAup_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Handling Missing Data\n",
        "\n",
        "Often data analysts need to account for missing data values.\n",
        "\n",
        "pandas uses the floating-point value NaN (Not a Number) to represent missing numerica data. This is a **sentinel** value that can be easily detected.\n",
        "\n",
        "The built-in Python `None` value is also treated as NA.\n",
        "\n",
        "pandas has several methods for detecting `NaN` values in a Series or DataFrame:\n",
        "- isnull\n",
        "- notnull\n",
        "\n",
        "These methods can be used as filters in a data query.\n",
        "\n",
        "`data[data.notnull()]`\n",
        "\n",
        "Alternatively, programs can use `dropna` to filter axis labels where values may have missing data. \n",
        "\n",
        "`dropna` has options to control how many missing values a row or column should have to be dropped.\n",
        "\n",
        "**replace missing values**\n",
        "Sometimes it's more useful to replace missing data with a specific or interpreted value, using `fillna`.\n",
        "\n",
        "`fillna` can use a function to determine fill value.\n",
        "\n",
        "`fillna` returns a new object, but has an `inplace` option."
      ],
      "metadata": {
        "id": "VutiVeS4BTte"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Simplifying Data\n",
        "\n",
        "- **removing duplicates** - DataFrames have built-in methods to identify which rows are `duplicated` and to `drop_duplicates`. By default, these methods consider all columns, but programs can specify a subset.\n",
        "\n",
        "- **replacing values** - the replace() method is a simple approach for replacing values in a pandas object.\n",
        "\n",
        "- **handling outliers** - programs may want to find & replace or filter values that exceed some threshold."
      ],
      "metadata": {
        "id": "YC6I94lKBnKP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### String Conversion\n",
        "\n",
        "python has a wide range of built-in string methods. Some common ones are:\n",
        "  - **split** - generate an array of substrings from a string based on a delimiter\n",
        "  - **lowercase** - convert a string to lower case\n",
        "  - **uppercase** - convert a string to upper case\n",
        "  - **join** - combine strings with a delimiter\n",
        "  - **index** - determine where in a string a substring is first found\n",
        "  - **find** - determine if a string contains a substring\n",
        "  - **count** - number of occurences of a substring in a string\n",
        "  - **replace** - substitute occurrences of one pattern with another.\n",
        "\n",
        "\n",
        "**Regular Expressions** provide a (mostly) language-agnostic logical syntax for finding/matching string patterns in text.\n",
        "\n",
        "`regex` patterns can be applied to strings with python's [re module](https://docs.python.org/3/library/re.html).\n",
        "\n"
      ],
      "metadata": {
        "id": "pjqwCL4VB7dr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "text = \"foo    bar\\t baz  \\tqux\"\n",
        "\n",
        "# inline regex pattern\n",
        "re.split('\\s+', text)\n",
        "\n",
        "# reusable regex object\n",
        "regex = re.compile('\\s+')\n",
        "regex.split(text)"
      ],
      "metadata": {
        "id": "SsYBLniBCOLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1B4F38nxHhX"
      },
      "source": [
        "### Hierarchical Indexing\n",
        "\n",
        "- allows multiple index (MultiIndex) levels on an axis\n",
        "- either axis of a DataFrame can have a hierarchical index\n",
        "- partial indexing allows concise selection of data subsets\n",
        "- selections can be made on the `outer` or `inner` level of a MultiIndex\n",
        "- can be used to reshape data (using `stack` & `unstack`)\n",
        "- can be used for group-based operations\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fR2iF-PETfB"
      },
      "source": [
        "#### Creating hierarchical indexes\n",
        "\n",
        "Hierarchical indexes can be assigned to dataset by passing a multi-dimensional list for the `index` value, with each list item having the same length as the dataset axis. This creates a `MultiIndex` object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARXVyZrxDulM",
        "outputId": "1f3f4b20-a90c-4490-b40d-7f83b2ca04e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "data = pd.Series(np.random.randn(9),\n",
        " index=[['a', 'a', 'a', 'b', 'b', 'c', 'c', 'd', 'd'],\n",
        " [1, 2, 3, 1, 3, 1, 2, 2, 3]])\n",
        "print(data)\n",
        "print(data.index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a  1   -0.605719\n",
            "   2    0.123044\n",
            "   3    1.811644\n",
            "b  1    0.823819\n",
            "   3    0.385486\n",
            "c  1    0.327702\n",
            "   2   -0.159786\n",
            "d  2    0.869689\n",
            "   3   -1.515328\n",
            "dtype: float64\n",
            "MultiIndex([('a', 1),\n",
            "            ('a', 2),\n",
            "            ('a', 3),\n",
            "            ('b', 1),\n",
            "            ('b', 3),\n",
            "            ('c', 1),\n",
            "            ('c', 2),\n",
            "            ('d', 2),\n",
            "            ('d', 3)],\n",
            "           )\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSij_o5gEPzD"
      },
      "source": [
        "#### Reordering & Sorting Levels\n",
        "\n",
        "- `swaplevel` changes order of levels in a MultiIndex\n",
        "- `sort_index` sorts the dataset using only the values in a single level of the MultiIndex\n",
        "\n",
        "#### Summary Statistics by Level\n",
        "\n",
        "- Many pandas descriptive and summary statistics support specifying the level you want to aggregate by on a particular axis. \n",
        "\n",
        "#### Indexing with DataFrame columns\n",
        "\n",
        "- DataFrame's `set_index` function will create a new DataFrame using one or more of its columns as the index\n",
        "- index columns are removed from the DataFrame unless specified otherwise with `drop=False`\n",
        "- `reset_index` moves hierarchical index levels into the DataFrame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdWMGl0syy32"
      },
      "source": [
        "### Combining & Merging Datasets\n",
        "\n",
        "pandas supports several different ways to combine datasets:\n",
        "\n",
        "- `pandas.merge` - connects rows in DataFrames based on one or more keys, like a SQL database join operation\n",
        "- `pandas.concat` - concatenates or 'stacks' data along an axis\n",
        "- `combine_first` instance method enables splicing together overlapping data to fill in missing values in one object with values from another.\n",
        "\n",
        "#### Database-style joins\n",
        "\n",
        "Merge or join operations combine datasets by linking rows using one or more keys.\n",
        "\n",
        "If column to join on is not specified, `merge` uses the overlapping column names as the keys.\n",
        "\n",
        "Different column names from each dataset can be specified as keys.\n",
        "\n",
        "By default `merge` does an `inner` join - the keys in the result are the intersection, or the common set found in both tables. Other possible options are `left`, `right`, and `outer` joins.\n",
        "\n",
        "To merge with multiple keys, pass a list of column names. \n",
        "\n",
        "`left_index=True` or `right_index=True` (or both) can indicate that the index should be used as the merge key\n",
        "\n",
        "DataFrame has a convenient `join` instance method for merging by index. It can also be used to combine together many DataFrame objects having the same or similar indexes but non-overlapping columns.\n",
        "\n",
        "#### Concatenation\n",
        "\n",
        "`concat` provides a consistent way to:\n",
        "- combine objects that are indexed differently\n",
        "- make the combined data identifiable in the resulting objects\n",
        "- preserve data in the concatenation axis\n",
        "\n",
        "By default `concat` works along axis=0, producing another Series. If you pass axis=1, the result will instead be a DataFrame (axis=1 is the columns)\n",
        "\n",
        "Concatenation along axis=1 supports an argument for type of `join` to use.\n",
        "\n",
        "Concatenation can create a hierarchical index on the concatenation axis using the `keys` argument.\n",
        "\n",
        "`ignore_index=True` allows drops the original indexes from the result.\n",
        "\n",
        "\n",
        "#### Combining data with overlap\n",
        "\n",
        "`combine_first` is similar to NumPy's `where` method for performing ternary operations.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLnZg7x8y-L7"
      },
      "source": [
        "### Reshaping & Pivoting\n",
        "\n",
        "#### Reshaping with Hierarchical Indexing\n",
        "#### Pivoting 'long' to 'wide'\n",
        "#### Pivoting 'wide' to 'long'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUCFb7WFHezB"
      },
      "source": [
        "### Grouping Data\n",
        "\n",
        "The expressiveness of Python and pandas allows complex group operations using any function that accepts a pandas object or NumPy array. This can include:\n",
        "\n",
        "- Splitting a pandas object into pieces using one or more keys\n",
        "- Calculating group summary statistics\n",
        "- Applying within-group transformations or other manipulations\n",
        "- Computing pivot tables and cross-tabulations\n",
        "- Performing quantile analysis and other statistical group analyses\n",
        "\n",
        "  #### GroupBy Operations\n",
        "\n",
        "Group operations involve the `split-apply-combine` mechanism.\n",
        "\n",
        "1. Data are split into groups based on one or more keys\n",
        "2. A function is applied to each group\n",
        "3. Results of the function application are combined into a new object\n",
        "\n",
        "Grouping keys can take many forms, and the keys do not have to be all of the same type.\n",
        "\n",
        "pandas `groupby` method returns a GroupBy object that can be re-used.\n",
        "\n",
        "DataFrame columns can be used as the group keys.\n",
        "\n",
        "Numeric aggregations will exclude `nuisance` (non-numeric) columns from the result\n",
        "\n",
        "By default `groupby` groups on axis=0, but can group on any of the other axes.\n",
        "\n",
        "  #### Iterating over groups\n",
        "\n",
        "The GroupBy object supports iteration, generating a sequence of 2-tuples containing the group name along with the chunk of data.\n",
        "\n",
        "Indexing a GroupBy object created from a DataFrame with a column name or array of column names has the effect of column subsetting for aggregation. This means that:\n",
        "```\n",
        "df.groupby('key1')['data1']\n",
        "```\n",
        "is essentially the same as:\n",
        "```\n",
        "df['data1'].groupby(df['key1'])\n",
        "```\n",
        "\n",
        "  #### Grouping with Series or Dicts\n",
        "\n",
        "\n",
        "  #### Grouping with Functions\n",
        "  #### Grouping by Index Levels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUH6j4_GIZ6G"
      },
      "source": [
        "### Data Aggregation\n",
        "\n",
        "Aggregations refer to any data transformation that produces scalar values from arrays.\n",
        "\n",
        "Programs can use built-in optimized aggregation methods, or custom functions.\n",
        "\n",
        "Programs can pass any function that aggregates an array to the `aggregate` or `agg` method of a GroupBy object. \n",
        "\n",
        "Custom aggregation functions are generally much slower than the built-in optimized functions.\n",
        "\n",
        "#### Column-wise & Multiple-function application\n",
        "\n",
        "Providing a list of functions or function names, results in a DataFrame with column names taken from the functions. Programs can over-ride the default column name:\n",
        "\n",
        "`grouped_pct.agg([('foo', 'mean'), ('bar', np.std), peak_to_peak])`\n",
        "\n",
        "You can specify a list of functions to apply to all of the columns or different functions per column.\n",
        "\n",
        "#### Aggregated data without row indexes\n",
        "\n",
        "By default, the aggregated data result has an index, potentially hierarchical, composed from the unique group key combinations. You can disable this behavior in most cases by passing `as_index=False` to groupby."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uz28GdPMJXoh"
      },
      "source": [
        "### General split-apply-combine\n",
        "\n",
        "#### Suppressing Group Keys\n",
        "#### Quantile & Bucket Analysis\n",
        "#### Filling missing values\n",
        "#### Random sampling & permutation\n",
        "#### Group weighted average and correlation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSDvXZR4KE02"
      },
      "source": [
        "### Pivot Tables & Cross-Tabulation\n",
        "\n",
        "A pivot table is a data summarization tool that aggregates a table of data by one or more keys, arranging the data in a rectangle with some of the group keys along the rows and some along the columns.\n",
        "\n",
        "#### Pivot Tables\n",
        "DataFrame has a `pivot_table` method, and there is also a top-level `pandas.pivot_table` function.\n",
        "\n",
        "The `margins=True` argument computes partial totals across rows and columns of the result table.\n",
        "\n",
        "#### Cross-Tabulations\n",
        "\n",
        "A cross-tabulation (or crosstab) is a special case of a pivot table that computes group frequencies."
      ]
    }
  ]
}